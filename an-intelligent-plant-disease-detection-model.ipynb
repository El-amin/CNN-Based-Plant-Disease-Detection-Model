{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**An Intelligent Plant Disease Detection System Using CNN for Smart Hydroponics**\n\nAuthor:[Aminu Musa] Date created: 18/08/2022\nDescription: This notebook is based on the paper an Intelligent Plant Disease Detection model Presented at 2021 IEEE 14th International Symposium on Embedded Multicore/Many-core Systems-on-Chip (MCSoC), Singapore.\nThe paper investigated the usefulness of CNN in plant disease detection in smart  hydroponics for control Agriculture. \n* We were able to achieve SOTA of 98% but the model is to big to fit on the embeded devices intended to use in the hydrpoinc system. the complete paper can be found at: https://ieeexplore.ieee.org/abstract/document/9691971 or \nDOI: 10.1109/MCSoC51149.2021.00058. \n\n* We used Tensorflow and Keras when impletmeting this work, in this particular notebook, due to limited computational resources we used smaller dataset with fewer instances than the original dataset we used in the paper. \n\n* In this notebook we provides detailed explanation on how Tensorflow can be used to implement CNN from Scratch.\n","metadata":{}},{"cell_type":"markdown","source":"we start with the importing all the required libraries in the code block below","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pickle\nimport cv2\nimport tensorflow as tf\nfrom os import listdir\nfrom sklearn.preprocessing import LabelBinarizer\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import (BatchNormalization, Conv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\n)\nfrom tensorflow.keras import backend as K\nfrom sklearn.preprocessing import LabelBinarizer\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import img_to_array\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-20T20:15:18.925771Z","iopub.execute_input":"2022-08-20T20:15:18.926275Z","iopub.status.idle":"2022-08-20T20:15:26.530799Z","shell.execute_reply.started":"2022-08-20T20:15:18.926175Z","shell.execute_reply":"2022-08-20T20:15:26.529577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the code block below, we initialize some important parameters needed to build a good model\n1- we start with epochs which signifies the number of time the model can go over a training set iteratively.\n2- BS stands for Batch Size, the nuber of images that can be fetch at a time\n3- Default image size defines a unifrom size to all the images, because the model will expect to recieve images with uniform shapes as input.\n4- lastly we define the height, width and depth of an image. ","metadata":{}},{"cell_type":"code","source":"EPOCHS = 10\nBS = 32\ndefault_image_size = tuple((256, 256))\nimage_size = 0\nwidth=256\nheight=256\ndepth=3\ndirectory_root = \"../input/plantdisease\"","metadata":{"_uuid":"7c3354a78e21a1a62ad0c4689d0ab3238fb760d4","execution":{"iopub.status.busy":"2022-08-20T20:15:31.954611Z","iopub.execute_input":"2022-08-20T20:15:31.955344Z","iopub.status.idle":"2022-08-20T20:15:31.961260Z","shell.execute_reply.started":"2022-08-20T20:15:31.955300Z","shell.execute_reply":"2022-08-20T20:15:31.960032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we used the built in keras function img_to_array to preprocess our images and convert them into numpy array ","metadata":{"_uuid":"2bf7ac0a0b805946f844a48e55d5281403e53f57"}},{"cell_type":"code","source":"def convert_image_to_array(image_dir):\n    try:\n        image = cv2.imread(image_dir)\n        if image is not None :\n            image = cv2.resize(image, default_image_size)   \n            return img_to_array(image)\n        else :\n            return np.array([])\n    except Exception as e:\n        print(f\"Error : {e}\")\n        return None","metadata":{"_uuid":"c9c3e60b13ace6c8f3e54336e12f9970fde438a3","execution":{"iopub.status.busy":"2022-08-20T20:15:39.950212Z","iopub.execute_input":"2022-08-20T20:15:39.950610Z","iopub.status.idle":"2022-08-20T20:15:39.957711Z","shell.execute_reply.started":"2022-08-20T20:15:39.950578Z","shell.execute_reply":"2022-08-20T20:15:39.956521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"in code block below we tried to fetch all the images and thier corresponsing labels from dataset directory and saved them in an image list And labels list respectively. in each sub directory we check to see if there is DS file and remove it. We fetch anything that ends with .jpg signifying that its an image file, alongside the corresponding labels.","metadata":{"_uuid":"24d42b87fad54a9556f78357ce673cc5152468c1"}},{"cell_type":"code","source":"image_list, label_list = [], []\ntry:\n    print(\"[INFO] Loading images ...\")\n    root_dir = listdir(directory_root)\n    \n    for directory in root_dir :\n        # remove .DS_Store from list\n        if directory == \".DS_Store\" :\n            root_dir.remove(directory)\n            \n    for plant_folder in root_dir :\n        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n        \n        for disease_folder in plant_disease_folder_list :\n            # remove .DS_Store from list\n            if disease_folder == \".DS_Store\" :\n                plant_disease_folder_list.remove(disease_folder)\n        for plant_disease_folder in plant_disease_folder_list:\n            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n            plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}/\")\n                \n            for single_plant_disease_image in plant_disease_image_list :\n                if single_plant_disease_image == \".DS_Store\" :\n                    plant_disease_image_list.remove(single_plant_disease_image)\n            for image in plant_disease_image_list[:200]:\n                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"\n                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n                    image_list.append(convert_image_to_array(image_directory))\n                    label_list.append(plant_disease_folder)\n    print(\"[INFO] Image loading completed\")  \n    \n        \n    \n    \nexcept Exception as e:\n    print(f\"Error : {e}\")","metadata":{"execution":{"iopub.status.busy":"2022-08-20T20:15:44.822068Z","iopub.execute_input":"2022-08-20T20:15:44.822478Z","iopub.status.idle":"2022-08-20T20:16:09.983143Z","shell.execute_reply.started":"2022-08-20T20:15:44.822444Z","shell.execute_reply":"2022-08-20T20:16:09.982049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"the label binarizer we imported from SK learn helps transform image Labels  into numpy array, which can be predicted by the model","metadata":{"_uuid":"905b41b226f3fd82a88e67821eb42a07f24b31f7"}},{"cell_type":"code","source":"label_binarizer = LabelBinarizer()\nimage_labels = label_binarizer.fit_transform(label_list)\npickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\nn_classes = len(label_binarizer.classes_)","metadata":{"_uuid":"904ff893fe14f5060dd9e7be2ccf96ec793597e5","execution":{"iopub.status.busy":"2022-08-20T20:16:18.622670Z","iopub.execute_input":"2022-08-20T20:16:18.623786Z","iopub.status.idle":"2022-08-20T20:16:18.644132Z","shell.execute_reply.started":"2022-08-20T20:16:18.623743Z","shell.execute_reply":"2022-08-20T20:16:18.642984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (n_classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Print the classes","metadata":{"_uuid":"f860c29a1d714f06d25e6a0c5bca94739e5d24cc"}},{"cell_type":"markdown","source":"Next thing, is to tranform the image list into numpy array for easier manipulation, and normalized the values by dividing through by 225","metadata":{}},{"cell_type":"code","source":"np_image_list = np.array(image_list, dtype=np.float16) / 225.0","metadata":{"_uuid":"6cd9c977b3d164a5570a0c24fdd8624adb9d56b8","execution":{"iopub.status.busy":"2022-08-20T20:16:25.926387Z","iopub.execute_input":"2022-08-20T20:16:25.926828Z","iopub.status.idle":"2022-08-20T20:16:37.864470Z","shell.execute_reply.started":"2022-08-20T20:16:25.926792Z","shell.execute_reply":"2022-08-20T20:16:37.863343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Another sk learn package train_test_split was used here to divide the dataset into two separate sets, normally called training and testing sets. ","metadata":{}},{"cell_type":"code","source":"print(\"[INFO] Spliting data to train, test\")\nx_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42)\n","metadata":{"_uuid":"9f4829560fdfa218cee18c1cfb2eb9452ef180e5","execution":{"iopub.status.busy":"2022-08-20T20:16:42.860411Z","iopub.execute_input":"2022-08-20T20:16:42.860805Z","iopub.status.idle":"2022-08-20T20:16:43.347381Z","shell.execute_reply.started":"2022-08-20T20:16:42.860772Z","shell.execute_reply":"2022-08-20T20:16:43.346197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We used tesnorflow package Imagedatagenerator to augment our dataset for better generalization and performance, Note: Augmentation here refers to the process of changing the normal image attributes such as rotating to diffent angle zoom in, to create another imaginary images that are not present in the dataset.\n","metadata":{}},{"cell_type":"code","source":"'''\naug = ImageDataGenerator(\n    rotation_range=25, width_shift_range=0.1,\n    height_shift_range=0.1, shear_range=0.2, \n    zoom_range=0.2,horizontal_flip=True, \n    fill_mode=\"nearest\")\n'''","metadata":{"_uuid":"eec8afa64e676d52c814fc8e096955a60f13b6c5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Model architecture is define below:  it takes images as input with uniform shape as defined in the beginging of the notebook, followed by 5 convolutional layer, each with a relu activation function. Then a drop out layer was added and and flattening layer before final dense layer with n_classes number of neurons and a softmax activation fun ioin to obtain the predicted probabilities.","metadata":{}},{"cell_type":"code","source":"\nmodel = Sequential()\ninputShape = (height, width, depth)\nchanDim = -1\nif K.image_data_format() == \"channels_first\":\n    inputShape = (depth, height, width)\n    chanDim = 1\nmodel.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(n_classes))\nmodel.add(Activation(\"softmax\"))","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2022-08-20T20:17:07.222639Z","iopub.execute_input":"2022-08-20T20:17:07.223081Z","iopub.status.idle":"2022-08-20T20:17:08.014081Z","shell.execute_reply.started":"2022-08-20T20:17:07.223044Z","shell.execute_reply":"2022-08-20T20:17:08.013050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model Summary","metadata":{"_uuid":"53b13c03e4cea6dc2453a84e254b806ebeed2d99"}},{"cell_type":"markdown","source":"The function model.summary() print the tabular form of the model architecture with the number of parameters available in the model","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"_uuid":"1e1523a834fbf872940171fbdefb3dcce2b5f31b","execution":{"iopub.status.busy":"2022-08-20T20:17:28.383517Z","iopub.execute_input":"2022-08-20T20:17:28.383977Z","iopub.status.idle":"2022-08-20T20:17:28.393656Z","shell.execute_reply.started":"2022-08-20T20:17:28.383926Z","shell.execute_reply":"2022-08-20T20:17:28.392627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model.compile applies loss function and an optimizer to the model, allowing the learning process and optimiztion to take place.","metadata":{}},{"cell_type":"code","source":"\nmodel.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer=keras.optimizers.Adam(learning_rate=0.0001),metrics=[\"accuracy\"])\n\n","metadata":{"_uuid":"b21dffee32c325136b4ea23ac511049723f34a24","execution":{"iopub.status.busy":"2022-08-20T20:18:17.124135Z","iopub.execute_input":"2022-08-20T20:18:17.124909Z","iopub.status.idle":"2022-08-20T20:18:17.141161Z","shell.execute_reply.started":"2022-08-20T20:18:17.124870Z","shell.execute_reply":"2022-08-20T20:18:17.140001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model.fit() commences the traning of the model saving the accuracy for each epoch in the history variable.","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n    x_train, y_train, batch_size=BS,\n    validation_data=(x_test, y_test),\n    steps_per_epoch=len(x_train) // BS,\n    epochs=EPOCHS, verbose=1\n    )","metadata":{"_uuid":"1a13efc5ded339fc3c0d9e61041e8ca555362db0","execution":{"iopub.status.busy":"2022-08-20T20:27:03.138906Z","iopub.execute_input":"2022-08-20T20:27:03.139644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot the train and val curve","metadata":{"_uuid":"1495fea08b37e4d4293f975ba30e6c1fc7a85ed9"}},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nprint(range(1, len(acc) + 1))\n\nepochs = range(1, len(acc) + 1)\n#Train and validation accuracy\nplt.plot(epochs, acc, 'b', label='Training accurarcy')\nplt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\nplt.title('Training and Validation accurarcy')\nplt.legend()\n\n\n\nplt.figure()\n#Train and validation loss\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\nplt.show()","metadata":{"_uuid":"0af5e0f23657a4effc2d21cf8e840e81f42ec8e7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Print the model Accuracy","metadata":{"_uuid":"9ca1a4489bd624c69a13cd37c0c2306ac8de55c2"}},{"cell_type":"code","source":"print(\"[INFO] Calculating model accuracy\")\nscores = model.evaluate(x_test, y_test)\nprint(f\"Test Accuracy: {scores[1]*100}\")","metadata":{"_uuid":"bb44f3d0b7e2862bc7d1a032612ebfd48212c1fe","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Save the model using Pickle","metadata":{"_uuid":"2a1f759db8afe933e62fe4cf8332cb303bb11be8"}},{"cell_type":"code","source":"# save the model to disk\nprint(\"[INFO] Saving model...\")\npickle.dump(model,open('cnn_model.pkl', 'wb'))''","metadata":{"_uuid":"5cdf06adf492d79ed28fbdc36e02ad7489c7b33e","trusted":true},"execution_count":null,"outputs":[]}]}